<!DOCTYPE html>
<!-- saved from url=(0098)https://www.softconf.com/acl2019/papers/user/scmd.cgi?scmd=authorResponse&passcode=713X-P6C6D3P7F4 -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<title>Reviews ACL 2019:The 57th Annual Meeting of the Association for Computational Linguistics</title>




<script type="text/javascript" src="./reviews_files/XulMenu.js"></script>



<script type="text/javascript" src="./reviews_files/utils.js"></script>



<script type="text/javascript" src="./reviews_files/tabpane.js"></script>





<script type="text/javascript" src="./reviews_files/jquery-3.3.1.min.js"></script>
<script type="text/javascript" src="./reviews_files/jquery-ui.min.js"></script>
<link type="text/css" href="./reviews_files/jquery-ui.min.css" rel="stylesheet">


<script type="text/javascript" src="./reviews_files/jquery.dialogextend.js"></script>
<script type="text/javascript" src="./reviews_files/jquery.form.js"></script> 
<script type="text/javascript" src="./reviews_files/jquery.jeditable.js"></script> 
<script type="text/javascript" src="./reviews_files/jquery.startutils.js"></script> 

<script type="text/javascript">
     jQuery.noConflict();
</script>



<script type="text/javascript" src="./reviews_files/jquery.specialedit.js"></script> 
<script type="text/javascript" src="./reviews_files/jquery.specialedit2.js"></script> 



<script type="text/javascript" src="./reviews_files/jquery.datetimepicker.js"></script> 
<link type="text/css" href="./reviews_files/jquery.datetimepicker.css" rel="stylesheet">




<script language="javascript" type="text/javascript" src="./reviews_files/edit_area_full.js"></script>



<script language="javascript" type="text/javascript" src="./reviews_files/tinymce.min.js"></script>



<script type="text/javascript" src="./reviews_files/diffview.js"></script>
<script type="text/javascript" src="./reviews_files/difflib.js"></script>


<style>

<!--
  @import url(https://www.softconf.com/acl2019/css/start.css); /* start CSS */
  @import url(https://www.softconf.com/acl2019/css/topmenu.css); /* topmenu CSS */
  @import url(https://www.softconf.com/acl2019/css/schedulemaker.css); /* schedulemaker CSS */
  @import url(https://www.softconf.com/acl2019/css/submitPaper.css); /* submitpaper CSS */
  @import url(https://www.softconf.com/acl2019/css/tab.css); /* tab CSS */

  @import url(https://www.softconf.com/acl2019/css/diffview.css); /* diffview CSS */

-->

</style>



</head>
<body bgcolor="#ffffff">
<script>
// Window should go back to same place upon reload
//
jQuery(window).scroll(function() {
  sessionStorage.scrollTop = jQuery(this).scrollTop();
});

jQuery(document).ready(function() {
  if (sessionStorage.scrollTop != "undefined") {
    jQuery(window).scrollTop(sessionStorage.scrollTop);
  }
});
</script>



<script type="text/javascript">
  jQuery(function() {
    
      setSpecialedit(); // this must be before settooltip because it uses tips
    
    setToolTip();
  });
</script>

<!-- empty conference banner; can be customized by customized installations -->

<div style="width=100%; COLOR: #000000; BACKGROUND-COLOR: #ffffff; border-top: 24px solid #1076BE; padding-left: 10px; padding-righ: 10px;">


<h2 align="center">The 57th Annual Meeting of the Association for Computational Linguistics</h2>

<h1 align="center"><a href="http://acl2019.org/">ACL 2019</a></h1>

<p align="center"><big>Review Report</big></p>
<p align="left">
</p><hr>
<p align="left">   

</p><table>

<tbody><tr>
<td align="right" valign="top">
<u>Title:</u>
</td>
<td align="left" valign="top">The Language of Legal and Illegal Activity on the Darknet</td>
</tr>

<tr>
<td align="right" valign="top">
<u>Authors</u>:
</td>
<td align-left="" valign="top">Leshem Choshen, Dan Eldad, Daniel Hershcovich, Elior Sulem and Omri Abend
</td>
</tr>

<tr>
<td align="right" valign="top">
<u>Status</u>:
</td>
<td align-left="" valign="top">Accept
</td>
</tr>



</tbody></table>
<p>

</p><div align="center">
<div style="border:2px solid #0077b3; padding:10px; width: 90%; text-align: left">
<table border="0" align="center" cellpadding="4">
<tbody><tr>
<td align="center">
<big>
Review #1
</big>
</td>
</tr></tbody></table>
<blockquote>
      <h4>What is this paper about, what contributions does it make, what are the main strengths and weaknesses?</h4>
	  <blockquote>
          This work analyzes the linguistic characteristics of the Darknet (so-called "the Onion sites") that is not covered by search engines, focusing on three domains of dark and non-dark sites — legal and illegal Onion pages, and also legal pages from eBay. Firstly they focused on NER and Wikification on these pages and found that Wikification works less well on illegal pages. Secondly, they ran a predictive analysis on these three domains by training domain classifiers using various features and algorithms. The analysis revealed that legal and illegal domains have distinguishable distributions of content words as well as syntactic patterns.<p></p>

<p>Strength:
  * A socially and legally important study that focuses on text characteristics of legal and illegal text in the Darknet
  * Detailed and varied analysis of the target domains using various NLP techniques (similarities, NER/Wikification, domain classification)
  * The paper is well written and can be easily followed</p>

<p>Weakness:
  * This is basically an elaborated text analysis report. Although I do not deny the importance of such work, when put in perspective, it is unclear how this work would contribute to the future of other domains and/or the NLP community in general. Some other venues (maybe socio-linguistic conferences) might be more appropriate.</p>
	  </blockquote>

      <h4>Reasons to accept</h4>
	  <blockquote>
          This type of domain is not discussed frequently in the ACL community, and it is socially important work. (although there are many other socially-important domains that are not discussed frequently in ACL)<p></p>
	  </blockquote>

      <h4>Reasons to reject</h4>
	  <blockquote>
          As mentioned above, the paper reads like a domain-specific text analysis report. It is unclear how much impact this would have on other domains and other NLP applications.<p></p>
	  </blockquote>

<div style="border:1px solid black; padding-left:10px"><table><tbody><tr><td align="right"><b>Overall Recommendation</b>:</td><td align="left">2.5</td></tr></tbody></table></div>      <h4>Questions and Suggestions for the Author(s)</h4>
	  <blockquote>
          Line 331: did you use all the entity types (person, organization, gpe, product, ...) that can be detected by spaCy? Isn't this too coarse-grained? Do types other than product (e.g., person and organization) even give any useful information?<p></p>

<p>Line 412: when you use GloVe embeddings, what happens to OOV words? Have you considered using FastText, which incorporates sub-word information?</p>

<p>Line 419: is the BiLSTM single-layered?</p>

<p>Figure 2 is a bit difficult to understand. You could possibly highlight distinguishing patterns that have higher weights in a classifier.</p>
	  </blockquote>


</blockquote>

</div>
</div>
<br><div align="center">
<div style="border:2px solid #0077b3; padding:10px; width: 90%; text-align: left">
<table border="0" align="center" cellpadding="4">
<tbody><tr>
<td align="center">
<big>
Review #2
</big>
</td>
</tr></tbody></table>
<blockquote>
      <h4>What is this paper about, what contributions does it make, what are the main strengths and weaknesses?</h4>
	  <blockquote>
          This study investigates the linguistic characteristics of legal and illegal texts in the Dark net and takes drug-related websites as an analysis target. An Onion corpus with drugs sub-domain is selected from the DUTA-10k corpus, accompanying a similar eBay corpus from clean net sources is compiled as a control condition, are both used as experimental data. Existing classification methods are adapted to verify the effects of founded linguistic features for categorization evaluation.<p></p>

<p>Strengths:</p>

<p>1.&nbsp;&nbsp;&nbsp;&nbsp;The research topic is interesting and rarely addressed. 
2.&nbsp;&nbsp;&nbsp;&nbsp;This paper is easy to follow and understand due to good readability. </p>

<p>Weakness: </p>

<p>1.&nbsp;&nbsp;&nbsp;&nbsp;No novel computational method is proposed. This work basically belongs to corpus linguistics area in exploring and finding linguistics features that can be used for classification.
2.&nbsp;&nbsp;&nbsp;&nbsp;The motivation and application scenario is unclear. Supposed the darknet is not easily reachable, to analyze the website of the “.onion” Top-Level Domain (TLD) seems not to reflect the realistic illegal events due to they can be filtered and blocked by TLD matching easily. 
3.&nbsp;&nbsp;&nbsp;&nbsp;The research scope is relatively small and limited. There are many objectionable domains in the darknet such as weapons, abortion, violence, racism and so on. Only analyzing drug-related content is not sufficient. Besides, marijuana is not legal in many countries even that can be sold as items in the eBay website.</p>
	  </blockquote>

      <h4>Reasons to accept</h4>
	  <blockquote>
          The research topic is rarely addressed. The paper is well written with focused but small contributions.<p></p>
	  </blockquote>

      <h4>Reasons to reject</h4>
	  <blockquote>
          No novel method is proposed, only evaluating using existing approaches, although linguistic features are found for legal/illegal text classification. The research scope is relatively small and limited, in the meanwhile, no application scenario is shown.<p></p>
	  </blockquote>

<div style="border:1px solid black; padding-left:10px"><table><tbody><tr><td align="right"><b>Overall Recommendation</b>:</td><td align="left">2.5</td></tr></tbody></table></div>      <h4>Questions and Suggestions for the Author(s)</h4>
	  <blockquote>
          I would suggest the authors referring to related studies from perspectives of information retrieval and web research area. From that, this research topic belongs to objectionable content filtering. Users’ searching/browsing behaviors are main focuses in recent years, rather than the content itself. Because objectionable content varies frequently to avoid being filtered by the software easily. Linguistic features from content may be out-of-date for filtering concerns.<p></p>
	  </blockquote>


</blockquote>

</div>
</div>
<br><div align="center">
<div style="border:2px solid #0077b3; padding:10px; width: 90%; text-align: left">
<table border="0" align="center" cellpadding="4">
<tbody><tr>
<td align="center">
<big>
Review #3
</big>
</td>
</tr></tbody></table>
<blockquote>
      <h4>What is this paper about, what contributions does it make, what are the main strengths and weaknesses?</h4>
	  <blockquote>
          This paper analyzes lexical, syntactic as well as stylistic differences between legal and illegal darknet page content (from onion domains) compared to classical non-darknet content such as from ebay. It analyzes differences in vocabulary measuring divergence using JS divergence as well as related methods. It also analyzes differences in number of NEs detected. <p></p>

<p>It analyzes how easy it is to classify pages into whether they feature legal or illegal content, using standard BOW based approaches, NB and SVM through to seq2vec and attention models. </p>

<p>The results are interesting but rather unsurprising showing that:</p>

<ul>
<li><p>legal darknet content is distinguishable from ebay content showing that a NB classifier can reach 91.4% accuracy on this task.
. distinguishing legal from illegal content on darket on drugs is more challenging (70.7% accuracy)</p></li>
<li><p>the legal vs. illegal detection on forums is in turn shown to achieve reasonable accuracy (85.3%)</p></li>
<li><p>a cross-domain setting training on drugs and evaluating on forums delivers better results compared to an in-domain setting; the conclusion is that illegal texts on the onion domain share characteristic independently of the domain</p></li>
<li><p>dropping content words leads to worse results (89.7 - &gt; 70%), this being a rather expected result IMHO</p></li>
</ul>

<p>The last aspect is interesting but is not analyzed further / in depth. </p>

<p>Overall the results are interesting, but methodologically the paper does not introduce any novelty.</p>
	  </blockquote>

      <h4>Reasons to accept</h4>
	  <blockquote>
          Interesting analysis of dark web material and empirical analysis on the ability to discriminate between legal and illegal content on the darknet and discriminating between darket and classical web content.<p></p>
	  </blockquote>

      <h4>Reasons to reject</h4>
	  <blockquote>
          Results are not very surprising; methodology is standard with little novelty<p></p>
	  </blockquote>

<div style="border:1px solid black; padding-left:10px"><table><tbody><tr><td align="right"><b>Overall Recommendation</b>:</td><td align="left">3</td></tr></tbody></table></div>
</blockquote>

</div>
</div>
<br>

<p>
</p><hr>
<p>
</p><p align="center">

<small>
<a href="http://www.softconf.com/" target="_blank">START</a> 
Conference Manager (V2.61.0 - Rev. 5835)
</small>
</p><p>&nbsp;
</p></div>

<div role="log" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>